{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb14ae73",
   "metadata": {
    "id": "fb14ae73"
   },
   "source": [
    "# Projet Machine Learning : prédiction de la consommation électrique du bâtiment GreEn-Er."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e28dcf7",
   "metadata": {
    "id": "1e28dcf7"
   },
   "source": [
    "## 1. Lecture et accès aux données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9873a282",
   "metadata": {
    "id": "9873a282"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192669e9",
   "metadata": {
    "id": "192669e9"
   },
   "outputs": [],
   "source": [
    "def loadData(fileName):\n",
    "    return pd.read_csv(fileName, index_col=0, parse_dates=True, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc56f033",
   "metadata": {
    "id": "bc56f033"
   },
   "outputs": [],
   "source": [
    "data_folder = Path('data') # les données sont dans le fichier 'data'\n",
    "csvFile = data_folder / 'conso_globale.csv' # accès au fichier 'conso_globale.csv'\n",
    "df = loadData(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bd4019",
   "metadata": {
    "id": "b0bd4019"
   },
   "outputs": [],
   "source": [
    "# affichage du DataFrame\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b3e1c",
   "metadata": {
    "id": "b59b3e1c"
   },
   "source": [
    "## 2. Preprocessing des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713eae9",
   "metadata": {
    "id": "8713eae9"
   },
   "source": [
    "### 2.1. Données manquantes de température."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1845aab0",
   "metadata": {
    "id": "1845aab0",
    "outputId": "c67951bf-d97b-4df5-db67-3db1f18076f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utilisation des données de 'conso_globale' pour avoir accès à la température\n",
    "# compléter les valeurs manquantes avec les voisins les plus proches (nearest neighbors)\n",
    "it_na = np.where(df['Temperature'].isna())[0]\n",
    "\n",
    "# it_na affiche les coordonnées des valeurs manquantes\n",
    "temp_impute = df['Temperature'].fillna(method='bfill')\n",
    "\n",
    "# on complète les valeurs manquantes avec .filla et bfill (on utilise la valeur suivante qui est correcte)\n",
    "np.any(temp_impute.isna())\n",
    "\n",
    "# df.isna()\n",
    "# affiche False car il ne manque pas de valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70312f11",
   "metadata": {
    "id": "70312f11",
    "outputId": "9ba398d5-e648-4b66-808a-c66255e30e92"
   },
   "outputs": [],
   "source": [
    "plt.subplots(2,1,figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.plot(temp_impute)\n",
    "# temp_impute[i_na].plot(subplots=True,color='r')\n",
    "plt.stem(np.asarray(temp_impute[it_na].index,dtype=object),temp_impute[it_na].values,markerfmt='ro',use_line_collection=True)\n",
    "\n",
    "# zoom sur 2017\n",
    "plt.subplot(2,1,2)\n",
    "# creation d'une variable avec les données de \"2017-03-01\" à \"2017-05-31\"\n",
    "year2017 = temp_impute[\"2017-03-01\":\"2017-05-31\"]\n",
    "it_na_2017 = np.where(df['Temperature'][\"2017-03-01\":\"2017-05-31\"].isna())[0]\n",
    "plt.plot(year2017)\n",
    "plt.stem(np.asarray(year2017[it_na_2017].index,dtype=object),year2017[it_na_2017].values,markerfmt='ro',use_line_collection=True)\n",
    "plt.show()\n",
    "\n",
    "# en rouge : les données complétées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774a22e",
   "metadata": {
    "id": "3774a22e"
   },
   "outputs": [],
   "source": [
    "# on modifie le DataFrame en le remplaçant par celui complété\n",
    "df['Temperature'] = temp_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97ff27",
   "metadata": {
    "id": "7d97ff27"
   },
   "source": [
    "### 2.2. Données manquantes de consommation globale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38dcbe",
   "metadata": {
    "id": "9e38dcbe",
    "outputId": "5abc01b4-6350-4762-8924-07ae9c171085"
   },
   "outputs": [],
   "source": [
    "# df['Global Consumption'].isna() : contient les consommations globales heures par heures\n",
    "\n",
    "# df['Global Consumption'].isna()\n",
    "# affiche les heures et 'False' s'il ne manque pas de données, et 'True' sinon\n",
    "\n",
    "# ic_na affiche dans un vecteur les index des valeurs manquantes\n",
    "\n",
    "ic_na = np.where(df['Global Consumption'].isna())[0]\n",
    "\n",
    "# .fillna permet de compléter des données manquantes\n",
    "# on utilise la méthode 'bfill' càd que l'on complète les données manquantes avec la donnée prochaine que l'on possède\n",
    "# on vérifie qu'il n'y a désormais plus de données manquantes\n",
    "\n",
    "df['Global Consumption'] = df['Global Consumption'].fillna(method='bfill')\n",
    "conso_impute = df['Global Consumption']\n",
    "# On vérifie qu'il n'y a désormais plus de données manquantes.\n",
    "\n",
    "np.any(conso_impute.isna())\n",
    "\n",
    "# np.any teste s'il y a des élements de temp_impute.isna() qui affichent 'True'\n",
    "# elle affiche 'False' car il ne manque pas de valeurs. OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7935c",
   "metadata": {
    "id": "9bb7935c",
    "outputId": "8fcff08c-5972-4e1b-ff59-bb53b02f88df"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "# figsize(largeur, hauteur) en inches par défaut\n",
    "\n",
    "conso_impute.plot(subplots=True)\n",
    "# .plot permet de tracer par défaut la consommation énergétique en fonction de la date (heure)\n",
    "# subplots = True : permet de tracer chaque colonne de conso_impute dans un sous-graphique séparé\n",
    "\n",
    "plt.stem(np.asarray(conso_impute[ic_na].index,dtype=object),conso_impute[ic_na],markerfmt='ro',use_line_collection=True)\n",
    "\n",
    "# la fonction stem crée un graphique dans lequel chaque point de données est représenté par une ligne verticale\n",
    "# qui s'étend de l'axe des x à la valeur y du point\n",
    "# l'argument 'markerfmt' spécifie comment formater les marqueurs en haut de chaque tige\n",
    "# dans ce cas, les marqueurs sont des cercles rouges : 'ro'\n",
    "\n",
    "# conso_impute[ic_na] : contient les coordonnées des données complétées de consommation globale\n",
    "# conso_impute : contient toutes les données de consommation globale\n",
    "\n",
    "# use_line_collection=True : une valeur booléenne indiquant s'il faut utiliser un objet 'LineCollection'\n",
    "# pour dessiner les lignes sur le graphique\n",
    "# en le définissant à True, cela peut améliorer les performances lorsque l'on trace de grandes quantités de données\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b844d",
   "metadata": {
    "id": "148b844d"
   },
   "source": [
    "### 2.3. Données temporelles manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95503ffd",
   "metadata": {
    "id": "95503ffd"
   },
   "source": [
    "##### 2.3.1. On vérifie s'il manque ou non des données temporelles manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095c75e",
   "metadata": {
    "id": "9095c75e",
    "outputId": "16ecfcc8-1d3d-4589-e75b-61e1a6153c14"
   },
   "outputs": [],
   "source": [
    "diff = conso_impute.index - conso_impute.index[0]\n",
    "\n",
    "# diff : calcule la différence entre chaque valeur de l'index de conso_impute et la première valeur de cet index\n",
    "\n",
    "# conso_impute.index : renvoie l'ensemble des index de la DataFrame conso_impute\n",
    "\n",
    "# conso_impute.index[0] : renvoie la première valeur de cet ensemble,\n",
    "# c'est-à-dire la valeur de l'index située à la première ligne de la DataFrame\n",
    "\n",
    "# conso_impute.index - conso_impute.index[0] soustrait cette première valeur à chaque valeur de l'index de\n",
    "# la DataFrame, élément par élément\n",
    "\n",
    "# le résultat est une série nommée ici diff, qui contient la différence entre chaque index et le premier index de la DataFrame\n",
    "\n",
    "hours = ( diff.seconds // (3600) + diff.days*24 )\n",
    "\n",
    "# hours : contient le nombre total d'heures correspondant à chaque différence temporelle de la série diff\n",
    "# La variable hours est donc une série Pandas de même longueur que diff, contenant des valeurs numériques\n",
    "# représentant le temps écoulé depuis le début de la période de mesure, exprimé en heures\n",
    "\n",
    "# diff.seconds renvoie le nombre de secondes dans chaque différence temporelle de diff\n",
    "# (c'est-à-dire l'extraction de la partie de la différence temporelle qui représente les secondes)\n",
    "\n",
    "# diff.days renvoie le nombre de jours dans chaque différence temporelle de diff\n",
    "\n",
    "# diff.days*24 multiplie le nombre de jours dans chaque différence temporelle par 24 (le nombre d'heures\n",
    "# dans une journée), pour obtenir le nombre total d'heures correspondant à chaque différence temporelle\n",
    "\n",
    "diff_hours = hours[1:] - hours[:-1]\n",
    "\n",
    "# diff_hours : contient les différences de temps en heures entre chaque paire d'heures consécutives (soit 1h)\n",
    "\n",
    "# hours[1:] sélectionne toutes les valeurs de hours sauf la première\n",
    "# (c'est-à-dire toutes les valeurs à partir de l'indice 1)\n",
    "\n",
    "# hours[:-1] sélectionne toutes les valeurs de hours sauf la dernière\n",
    "# (c'est-à-dire toutes les valeurs jusqu'à l'avant-dernier indice)\n",
    "\n",
    "# hours[1:] - hours[:-1] soustrait à chaque valeur de hours sa valeur précédente, pour obtenir la différence\n",
    "# de temps entre chaque paire d'heures consécutives dans la série : soit 1h à chaque fois (normalement)\n",
    "\n",
    "time_gaps = np.where(diff_hours != 1)[0]\n",
    "\n",
    "# diff_hours != 1 crée un tableau NumPy de booléens avec des 'True' là où les valeurs de diff_hours\n",
    "# ne sont pas égales à 1 et 'False' sinon\n",
    "\n",
    "# np.where() trouve les indices des éléments dans le tableau où la valeur est 'True'.\n",
    "# Dans ce cas, np.where(diff_hours != 1) retourne un tuple contenant un seul élément qui est un vecteur\n",
    "# contenant les indices où les valeurs de diff_hours ne sont pas égales à 1\n",
    "\n",
    "# time_gaps est une variable qui reçoit ce tableau NumPy d'indices\n",
    "# Ces indices représentent les positions dans la série temporelle où se trouvent les \"trous\" de temps,\n",
    "# c'est-à-dire les points où il y a des intervalles de temps manquants entre les mesures\n",
    "\n",
    "print('WARNING! Missing samples:\\n{}'.format(conso_impute.index[time_gaps]))\n",
    "\n",
    "# conso_impute.index[time_gaps] extrait les dates et heures correspondant aux indices des échantillons manquants\n",
    "# dans la série temporelle\n",
    "\n",
    "# .format() permet d'insérer la liste des dates et heures manquantes dans le message\n",
    "\n",
    "# il manque bien des données temporelles que l'on doit combler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6cd3b",
   "metadata": {
    "id": "8ea6cd3b"
   },
   "source": [
    "##### 2.3.2. On complète les données manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cf14c",
   "metadata": {
    "id": "668cf14c",
    "outputId": "d78f8eee-878c-4bc9-f2d7-74208ec65db1"
   },
   "outputs": [],
   "source": [
    "# index où il y a des données manquantes\n",
    "time_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d481599",
   "metadata": {
    "id": "2d481599",
    "outputId": "8d777c4a-cca7-44aa-a02f-9a4715e81761"
   },
   "outputs": [],
   "source": [
    "# observation de la colonne à partir de laquelle on souhaite compléter nos données\n",
    "df.iloc[12119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8d588",
   "metadata": {
    "id": "dba8d588",
    "outputId": "b294fd7f-8b68-4822-a469-1d6ca7b1874a"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9d7d1",
   "metadata": {
    "id": "07a9d7d1"
   },
   "outputs": [],
   "source": [
    "# Suppression des lignes avec les index spécifiés (heures non \"entières\")\n",
    "\n",
    "# index des lignes à supprimer\n",
    "positions_to_drop = [24908, 24910, 24911]\n",
    "\n",
    "# Suppression des lignes\n",
    "df = df.drop(df.index[positions_to_drop])\n",
    "\n",
    "#df.index[positions_to_drop] permet d'obtenir la position des lignes à supprimer\n",
    "#df.drop() : supprime ces lignes du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663fc43",
   "metadata": {
    "id": "6663fc43",
    "outputId": "d16fa05e-9d9e-4902-9af8-2c19dc63398b"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8b170",
   "metadata": {
    "id": "c4e8b170"
   },
   "outputs": [],
   "source": [
    "# Ajouter les dates manquantes et les compléter avec la dernière consommation mesurée\n",
    "\n",
    "row_values = [150.7, 12.2] # valeurs de consommation globale et température\n",
    "insert_index = 0 # initialisation\n",
    "\n",
    "date_range = pd.date_range(start=\"2018-05-21 00:00:00\", end=\"2018-05-27 23:00:00\", freq=\"H\")\n",
    "# plage des dates que l'on souhaite ajouter\n",
    "\n",
    "# boucle :\n",
    "for date in date_range:\n",
    "    insert_row = pd.DataFrame({v: row_values[k] for k, v in enumerate(df.columns)}, index=[date])\n",
    "    insert_index += 1\n",
    "    df = df.iloc[:insert_index,].append([insert_row, df.iloc[insert_index:,]])\n",
    "\n",
    "# Chaque nouvelle ligne de type \"DataFrame\" est crée en utilisant les valeurs de row_values\n",
    "# Le dataframe 'df' est mis à jour en utilisant iloc pour diviser le dataframe à l'index 'insert_index'\n",
    "# et on insère la nouvelle ligne entre les deux parties du DataFrame\n",
    "#df.iloc() permet de sélectionner un ensemble de lignes connaissant leurs indices\n",
    "#df.append() permet d'ajouter une ligne à la fin du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5cd0d8",
   "metadata": {
    "id": "fc5cd0d8",
    "outputId": "988ac8e2-17be-4897-fa9a-b2b9459b256d"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a8363",
   "metadata": {
    "id": "bc3a8363"
   },
   "source": [
    "#### 2.3.3. On vérifie qu'il n'y a pas de données manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3af189",
   "metadata": {
    "id": "1a3af189"
   },
   "outputs": [],
   "source": [
    "conso = df['Global Consumption']\n",
    "temp = df['Temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4842861",
   "metadata": {
    "id": "c4842861",
    "outputId": "7373089d-bc21-45bd-b223-05ab2653286c"
   },
   "outputs": [],
   "source": [
    "np.where(conso.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535fc65",
   "metadata": {
    "id": "7535fc65",
    "outputId": "c72f3353-6b51-423d-c5d5-62c816405a03"
   },
   "outputs": [],
   "source": [
    "np.where(temp.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c4d73",
   "metadata": {
    "id": "c71c4d73"
   },
   "source": [
    "## 3. Redimensionnement des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1829eb",
   "metadata": {
    "id": "1c1829eb"
   },
   "source": [
    "### 3.1. Définition des paramètres du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec69447",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "1ec69447",
    "outputId": "25201d5e-3ee8-49d6-a4f7-7995341c26cf"
   },
   "outputs": [],
   "source": [
    "nsample = len(conso)\n",
    "# nombre total d'échantillons (ie. de données de consommation que l'on possède)\n",
    "\n",
    "# Sélection de la valeur passée à l'instant H\n",
    "num_days = 14 # number of days (avant changement = 7)\n",
    "# Nombre de jours utilisés pour l'historique de la prédiction\n",
    "# On veut utiliser les données des 2 semaines précédentes\n",
    "\n",
    "history = num_days * 24 + 1\n",
    "# history : représente le nombre total d'heures d'historiques utilisées pour la prédiction\n",
    "# L'historique commence à l'instant H de la journée D et remonte jusqu'à l'instant H de la journée D - 7\n",
    "\n",
    "# Prédiction à l'instant H + prévision (forecast)\n",
    "forecast = 24*7 # 24 h = 1 day ahead forecasting (avant changement = 24)\n",
    "\n",
    "# forecast : nombre d'heures d'avance pour lesquels on souhaite effectuer la prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8db0d0",
   "metadata": {
    "id": "cc8db0d0"
   },
   "source": [
    "### 3.2. Redimensionnement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b60d7f",
   "metadata": {
    "id": "a7b60d7f"
   },
   "outputs": [],
   "source": [
    "# Récupération de la consommation à l'instant H+forecast (H : heure)\n",
    "ya_target = conso[history+forecast-1:]\n",
    "\n",
    "# Extraction de la consommation d'énergie à partir de l'indice 'history+forecast-1' jusqu'à la fin\n",
    "# Ce sont les données que l'on souhaite prédire\n",
    "\n",
    "# Récupération des températures à l'instant H (+ éventuellement les valeurs passées)\n",
    "xa_temp = temp[history - 1 : nsample - forecast] # temp_imput voir plus haut (données de température)\n",
    "# On récupère les données de températures à partir de l'indice 'history-1' jusqu'à 'nsample-forecast',\n",
    "# ce qui correspond à la plage de temps où l'on dispose de données de température correspondantes\n",
    "\n",
    "# Récupération des valeurs passées de la consommation énergétique\n",
    "Xa = np.zeros( shape = (nsample-forecast-history+1, history) )\n",
    "for h in range(nsample - forecast - history + 1 ):\n",
    "    # Take past values\n",
    "    Xa[h,:] = conso[h : h + history]\n",
    "\n",
    "# On remplit chacune ligne avec les valeurs passées de consommation d'énergie\n",
    "\n",
    "# Inversion des variables prédictives pour obtenir la valeur actuelle en première colonne\n",
    "Xa = np.fliplr(Xa)  # fliplr : \"retourner\" le vecteur\n",
    "\n",
    "# Ajout de la température actuelle comme une caractéristique et concaténation à la dernière colonne de X\n",
    "Xa = np.concatenate( (Xa, xa_temp.to_numpy().reshape(-1, 1) ) ,axis = 1  )\n",
    "# to_numpy : convertie la donnée en un array numpy\n",
    "# Xa contient la consommation à un temps donnée (1e colonne) et la température (2e colonne) à ce temps donné\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6dc81",
   "metadata": {
    "id": "5aa6dc81"
   },
   "outputs": [],
   "source": [
    "# Vérification que les données x et y sont correctement enregistrées dans le vecteur temps\n",
    "print('starting time')\n",
    "print('{} (x_temp)'.format(xa_temp.index[0]))\n",
    "print('{} (current predictor X)'.format(conso[0:0+history].index[-1]))\n",
    "print('{} (last predictor X)'.format(conso[0:0+history].index[0]))\n",
    "print('{} (target y)'.format(ya_target.index[0]))\n",
    "\n",
    "print('ending time')\n",
    "print('{} (x_temp)'.format(xa_temp.index[-1]))\n",
    "print('{} (current predictor X)'.format(\n",
    "    conso_impute[(nsample-forecast-history):(nsample-forecast-history)+history].index[-1]))\n",
    "print('{} (last predictor X)'.format(\n",
    "    conso_impute[(nsample-forecast-history):(nsample-forecast-history)+history].index[0]))\n",
    "print('{} (target y)'.format(ya_target.index[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305238af",
   "metadata": {
    "id": "305238af"
   },
   "source": [
    "## 4. Machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd1ec0b",
   "metadata": {
    "id": "bbd1ec0b"
   },
   "source": [
    "### 4.1. Mettre les données à l'échelle (scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0c0cf",
   "metadata": {
    "id": "11e0c0cf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Mise à l'échelle (standardiser) les données\n",
    "sc = StandardScaler()\n",
    "Xa_s= sc.fit_transform(Xa)\n",
    "#StandardScaler() : Standardise les datas en enlevant la valeur moyenne.\n",
    "#fit_transform(Xa) : Calcul la moyenne et la norme pour transformer les data Xa en format compatible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4f277",
   "metadata": {
    "id": "4ec4f277"
   },
   "source": [
    "### 4.2. L'algorithme Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf18ff",
   "metadata": {
    "id": "facf18ff"
   },
   "source": [
    "#### 4.2.1. Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4d8c3",
   "metadata": {
    "id": "5bb4d8c3"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import  median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655d870",
   "metadata": {
    "id": "e655d870",
    "outputId": "0468bbb5-713c-46f0-9505-f8f55cb50dbd"
   },
   "outputs": [],
   "source": [
    "X = Xa_s #data d'entrainement\n",
    "y = ya_target #valeur cible\n",
    "\n",
    "max_depth = 15 # définition de la pronfondeur maximale de l'arbre\n",
    "\n",
    "regr_rf = RandomForestRegressor(n_estimators=100, max_depth=max_depth,\n",
    "                                random_state=0, oob_score=True,\n",
    "                                verbose=1,\n",
    "                                criterion='squared_error', # Rk: too time consumming with the more robust 'mae'\n",
    "                                n_jobs=-1)\n",
    "\n",
    "#Paramétrisation du modéle de prédiction de \"Random forest\". On initialise les différents paramétres de la fonction\n",
    "#pour pouvoir réaliser la régression de nos données.\n",
    "# n_estimator : définit le nombre d'arbre a créer dans la forêt\n",
    "# max_depth : définit le nombre maximale de noeuds par arbres\n",
    "# random_state : choix du générateur de nombre aléatoire\n",
    "# oob_scores : si true permet de calculer les scores du dataset d'entrainement\n",
    "# verbose : permet d'avoir plus d'information sur le procéssus de construction (bandeau rouge exécution)\n",
    "# criterion : calcules de la qualité (choix squarred error)\n",
    "# n_jobs : nombre de travaux réalisé en parralléles sur le processeur (-1 = maximum)\n",
    "\n",
    "regr_rf.fit(X,y) #réalise une forêt d'arbres via les données d'entrainement X et y la valeur cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adb644",
   "metadata": {
    "id": "d9adb644",
    "outputId": "4cd89b93-64ee-48d0-c6a4-7d660871d374"
   },
   "outputs": [],
   "source": [
    "y_rf_a= regr_rf.predict(X) #prédits de nouvelles données y_rf_a cibles selon X (via le modéle regr_rf.fit(X,y) )\n",
    "r2_train = r2_score(y_rf_a,y) #calcul du coefficient de détermination R2 pour évaluer la méthode (valeur max = 1.0)\n",
    "mad_train = median_absolute_error(y_rf_a,y) #Calcul de l'erreur medianne absolue (meilleur valeur 0.0)\n",
    "print('training error r2 = {}, MAD = {}'.format(r2_train,mad_train) ) #impressions de R2 et de l'erreur medianne absolue\n",
    "print('out of bag score (r2 estimaeted on non used data)= {}'.format(regr_rf.oob_score_)) # impression de R2 sur les données non estimé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac4e33",
   "metadata": {
    "id": "21ac4e33",
    "outputId": "f88b5749-6f59-46c9-ad1a-50ebd04099f4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(ya_target.values,'r')\n",
    "plt.plot(y_rf_a)\n",
    "plt.legend(['actual','pred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cae90",
   "metadata": {
    "id": "2b0cae90",
    "outputId": "ed98e63a-e2f8-4d62-fe55-54c927989cf1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(np.arange(len(regr_rf.feature_importances_)), regr_rf.feature_importances_) #affichage de l'influence des données utilisés\n",
    "plt.xticks(np.arange(0,24*14+1,24),labels=['D0','D-1','D-2','D-3','D-4','D-5','D-6', 'D-7','D-8','D-9','D-10','D-11','D-12','D-13','Temp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c146e14",
   "metadata": {
    "id": "2c146e14",
    "outputId": "8c9a8ba9-f65c-4f1f-a1f3-4109d47306a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation croisée\n",
    "ybis = conso_impute[history+forecast-1:]\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "groups = np.zeros(y.shape)\n",
    "years = ybis.index.year.to_numpy()\n",
    "for iy , year in enumerate(np.arange( years.min(),  years.max()+1 )):\n",
    "    gindex = np.where( years == year)[0]\n",
    "    groups[gindex] = iy\n",
    "\n",
    "cv = LeaveOneGroupOut()\n",
    "scoring = {'r2': 'r2', 'MAD': 'neg_median_absolute_error'}\n",
    "scores = cross_validate(regr_rf, X, y, cv=cv.split(X,y, groups),\n",
    "                        scoring = scoring)\n",
    "\n",
    "\n",
    "mad_test = np.mean(scores['test_MAD'])\n",
    "r2_test = np.mean(scores['test_r2'])\n",
    "print('test error r2 = {}, MAD = {}'.format(r2_test,mad_test) )\n",
    "print('out of bag score (r2 estimaeted on non used data)= {}'.format(regr_rf.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fd6db",
   "metadata": {
    "id": "f20c5a74"
   },
   "source": [
    "#### 4.2.2. Prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d5c8c",
   "metadata": {
    "id": "5a0d5c8c",
    "outputId": "101141ce-e429-4e34-b216-eee336d6d17e"
   },
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80, random_state=42)\n",
    "\n",
    "max_depth = 50 # définition de la pronfondeur maximale de l'arbre\n",
    "\n",
    "regr_rf = RandomForestRegressor(n_estimators=500, max_depth=max_depth,\n",
    "                                random_state=0, oob_score=True,\n",
    "                                verbose=1,\n",
    "                                criterion='squared_error',\n",
    "                                n_jobs=-1)\n",
    "\n",
    "regr_rf.fit(X_train,y_train) # réalisation une forêt d'arbres via les données d'entrainement X et y la valeur cible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dad5b",
   "metadata": {
    "id": "cc3dad5b",
    "outputId": "6c428bb9-0960-4a10-d25e-ce53dc845962"
   },
   "outputs": [],
   "source": [
    "y_rf_a= regr_rf.predict(X_test) #prédits de nouvelles données y_rf_a cibles selon X (via le modéle regr_rf.fit(X,y) )\n",
    "r2_train = r2_score(y_rf_a,y_test) #calcul du coefficient de détermination R2 pour évaluer la méthode (valeur max = 1.0)\n",
    "mad_train = median_absolute_error(y_rf_a,y_test) #Calcul de l'erreur medianne absolue (meilleur valeur 0.0)\n",
    "print('training error r2 = {}, MAD = {}'.format(r2_train,mad_train) ) #impressions de R2 et de l'erreur medianne absolue\n",
    "print('out of bag score (r2 estimaeted on non used data)= {}'.format(regr_rf.oob_score_)) # impression de R2 sur les données non estimé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888a14c",
   "metadata": {
    "id": "6888a14c",
    "outputId": "b08e6453-dc9d-443b-b933-a733d1681ad0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_test.values,'r')\n",
    "plt.plot(y_rf_a)\n",
    "plt.legend(['actual','pred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02d8e9",
   "metadata": {
    "id": "fb02d8e9",
    "outputId": "0e404316-c88d-4c25-e299-702136b06a00"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(np.arange(len(regr_rf.feature_importances_)), regr_rf.feature_importances_) #affichage de l'influence des données utilisés\n",
    "plt.xticks(np.arange(0,24*14+1,24),labels=['D0','D-1','D-2','D-3','D-4','D-5','D-6', 'D-7','D-8','D-9','D-10','D-11','D-12','D-13','Temp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438f3dd",
   "metadata": {
    "id": "c438f3dd",
    "outputId": "40dd3493-d598-482b-bd6a-bd010105eb85"
   },
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "ybis = conso_impute[history+forecast-1:]\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "groups = np.zeros(y.shape)\n",
    "years = ybis.index.year.to_numpy()\n",
    "for iy , year in enumerate(np.arange( years.min(),  years.max()+1 )):\n",
    "    gindex = np.where( years == year)[0]\n",
    "    groups[gindex] = iy\n",
    "cv = LeaveOneGroupOut()\n",
    "scoring = {'r2': 'r2', 'MAD': 'neg_median_absolute_error'}\n",
    "scores = cross_validate(regr_rf, X, y, cv=cv.split(X,y, groups),\n",
    "                        scoring = scoring)\n",
    "\n",
    "\n",
    "mad_test = np.mean(scores['test_MAD'])\n",
    "r2_test = np.mean(scores['test_r2'])\n",
    "print('test error r2 = {}, MAD = {}'.format(r2_test,mad_test) )\n",
    "print('out of bag score (r2 estimaeted on non used data)= {}'.format(regr_rf.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c7efb",
   "metadata": {
    "id": "cd9c7efb"
   },
   "source": [
    "### 4.3. L'algorithme de régression polynomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3ff7a",
   "metadata": {
    "id": "15b3ff7a"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import median_absolute_error,r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2fb16",
   "metadata": {
    "id": "50d2fb16"
   },
   "outputs": [],
   "source": [
    "#X=temp.to_numpy().reshape((-1,1))\n",
    "X1=Xa_s[:,-1] \n",
    "\n",
    "# Les Caractéristiques choisis -- Les température\n",
    "X=X1.reshape((-1,1))\n",
    "# On utilise .reshape((-1,1))pour redimensionner un tableau X1 en un tableau à deux dimensions (X) avec une seule\n",
    "# colonne. C'est la méthode de la classe NumPy ndarray utilisée pour remodeler le tableau. L'argument (-1, 1)\n",
    "# spécifie la nouvelle forme du tableau.\n",
    "# La valeur -1, il indique à NumPy d'inférer automatiquement la taille de cette dimension en fonction des autres\n",
    "# dimensions et de la taille totale du tableau. Ainsi, NumPy déterminera la taille appropriée pour cette dimension\n",
    "# afin de préserver le nombre total d'éléments du tableau.\n",
    "# La valeur 1 --> le tableau résultant doit avoir une seule colonne.\n",
    "# print(X)\n",
    "\n",
    "y=ya_target \n",
    "# Les valeurs cibles que l'on souhaite prédire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9808754",
   "metadata": {
    "id": "e9808754"
   },
   "outputs": [],
   "source": [
    "# Transformation des caractéristiques en utilisant un degré polynomial\n",
    "degree=6  \n",
    "\n",
    "# Degré du polynôme --> fait référence à l'ordre du polynôme utilisé pour modéliser la relation entre\n",
    "# (caractéristiques) et (cible). Le degré du polynôme détermine le nombre maximal de termes polynomiaux inclus\n",
    "# dans le modèle. Par exemple, un polynôme de degré 1 est une simple régression linéaire, tandis qu'un polynôme\n",
    "# de degré 2 est une régression quadratique...\n",
    "# Un degré plus élevé permet au modèle de mieux s'adapter aux données, mais il peut également conduire à un\n",
    "# surajustement si le degré est choisi de manière excessive par rapport à la complexité des données.\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "# utilisée pour générer de nouvelles caractéristiques en ajoutant des polynômes des caractéristiques d'origine.\n",
    "# permet d'effectuer une régression polynomiale.\n",
    "\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "# pour transformer les caractéristiques d'origine en des polynômes de degré spécifié à l'aide de la méthode\n",
    "# fit_transform().\n",
    "# ce qui peut permettre de modéliser des relations plus complexes entre les caractéristiques et la variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548743c",
   "metadata": {
    "id": "f548743c"
   },
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "# à l'aide d'une proportion de 80% pour l'ensemble d'entraînement et 20% pour l'ensemble de test.\n",
    "train_size = int(0.8 * nsample)\n",
    "X_train, X_test = X_poly[:train_size], X_poly[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15927d",
   "metadata": {
    "id": "6b15927d",
    "outputId": "d1c09361-1f03-4ede-b109-753a26e2d45c"
   },
   "outputs": [],
   "source": [
    "# Création du pipeline et Entraînement du modèle sur l'ensemble d'entraînement\n",
    "linear_regression = LinearRegression()\n",
    "Modele = Pipeline([(\"polynomial_features\", poly_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "# un modèle de régression linéaire utilisant la régression polynomiale en utilisant le pipeline.\n",
    "# Le pipeline lie lie l'objet 'poly_features' et 'linear_regression'\n",
    "\n",
    "Modele.fit(X_train, y_train)\n",
    "# --> ajuste le modèle sur les données d'entraînement\n",
    "# Après l'exécution, on obtient le modèle entraîné Modele qui incorpore à la fois la transformation des\n",
    "# caractéristiques en polynômes de degré spécifié et la régression linéaire pour prédire les valeurs cibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35055529",
   "metadata": {
    "id": "35055529",
    "outputId": "93640f69-7c5f-4b0e-87e2-85990cd56d60"
   },
   "outputs": [],
   "source": [
    "# Prédiction\n",
    "y_pred = Modele.predict(X_test)\n",
    "# Prédiction des valeurs cibles correspondantes aux caractéristiques de l'ensemble de test (X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941bbf7",
   "metadata": {
    "id": "0941bbf7",
    "outputId": "eae70d47-3438-4db0-d47b-a6ca7ddfc086"
   },
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "mad = median_absolute_error(y_test, y_pred) # Mean Absolute Error\n",
    "print(\"MAD:\", mad)\n",
    "r2 = r2_score(y_test, y_pred) # le coefficient de détermination\n",
    "print(\"R²:\", abs(r2))\n",
    "scores = cross_val_score(Modele, X_poly, y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "#print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebbaec",
   "metadata": {
    "id": "48ebbaec",
    "outputId": "a1fae3c9-2911-44eb-f87b-2946cd106518",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t=np.arange(len(X_test))\n",
    "plt.figure(facecolor='w')\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(t, y_test, 'r-', linewidth=2, label='Actual')\n",
    "plt.plot(t, y_pred, 'b-', linewidth=2, label='Predict')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title\n",
    "plt.grid(b=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0593d3ac",
   "metadata": {
    "id": "0593d3ac"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Modele' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Validation croisée du modèle pour évaluer ses performances\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m----> 4\u001b[0m scores\u001b[38;5;241m=\u001b[39mcross_val_score(Modele, X_poly, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Modele' is not defined"
     ]
    }
   ],
   "source": [
    "# Validation croisée du modèle pour évaluer ses performances\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores=cross_val_score(Modele, X_poly, y, cv=5,scoring='neg_mean_absolute_error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d7fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
